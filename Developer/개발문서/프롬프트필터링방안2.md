# PromptGate 모듈 상세 설계서

## 1. 시스템 아키텍처

### 1.1 전체 구성도
```
┌─────────────────┐    ┌──────────────────────────────────────┐    ┌─────────────┐
│   Client App    │───▶│           PromptGate Proxy           │───▶│  LLM Backend│
│                 │    │                                      │    │  (GPT/etc)  │
└─────────────────┘    └──────────────────────────────────────┘    └─────────────┘
                                      │
                       ┌──────────────┼──────────────┐
                       │              │              │
                ┌─────────────┐ ┌───────────┐ ┌─────────────┐
                │Policy Engine│ │Vector DB  │ │Audit Logger │
                │    (OPA)    │ │(Qdrant)   │ │(OpenSearch) │
                └─────────────┘ └───────────┘ └─────────────┘
```

### 1.2 프로세싱 파이프라인
```
[Input] → [Auth] → [Normalize] → [Filter Stack] → [Sanitize] → [LLM] → [Output Filter] → [Response]
                                      │
                    ┌─────────────────┼─────────────────┐
                    │                 │                 │
            [Static Filter]  [ML Classifier]  [Embedding Filter]
                    │                 │                 │
            [Secret Scanner] [PII Detector]  [Injection Detector]
```

## 2. 핵심 컴포넌트 설계

### 2.1 인증 및 라우팅 레이어
```python
@dataclass
class RequestContext:
    tenant_id: str
    user_id: str
    session_id: str
    request_id: str
    timestamp: datetime
    client_ip: str
    user_agent: str
    
class AuthenticationHandler:
    async def authenticate(self, request: Request) -> RequestContext:
        # JWT/API Key 검증
        # 테넌트/사용자 식별
        # RBAC 권한 확인
        pass
```

### 2.2 정책 엔진 (OPA 기반)
```python
class PolicyEngine:
    def __init__(self):
        self.opa_client = OPAClient()
        self.policies = {}
    
    async def evaluate(self, context: RequestContext, prompt: str) -> PolicyResult:
        """
        Rego 정책 평가:
        - 테넌트별 규칙 적용
        - 사용자 권한 체크
        - 컨텐츠 분류 결과 반영
        """
        input_data = {
            "tenant": context.tenant_id,
            "user": context.user_id,
            "prompt": prompt,
            "metadata": self.extract_metadata(prompt)
        }
        return await self.opa_client.query("data.promptgate.allow", input_data)

# Rego 정책 예시
```
package promptgate

default allow = false

allow {
    input.tenant == "kra-internal"
    not contains_secrets(input.prompt)
    not contains_injection(input.prompt)
    user_has_permission(input.user)
}

contains_secrets(prompt) {
    regex.match("(?i)password|secret|token", prompt)
}
```

### 2.3 필터 스택 구현

#### Static Pattern Filter
```python
class StaticPatternFilter:
    def __init__(self, config: Dict):
        self.deny_patterns = [re.compile(p, re.IGNORECASE) for p in config.get("deny_patterns", [])]
        self.vectorscan = load_vectorscan_db(config.get("pattern_db"))
    
    async def filter(self, prompt: str) -> FilterResult:
        # Regex 패턴 매칭
        for pattern in self.deny_patterns:
            if pattern.search(prompt):
                return FilterResult(
                    action="block",
                    reason="matched_deny_pattern",
                    confidence=1.0
                )
        
        # Vectorscan 고성능 패턴 매칭
        matches = self.vectorscan.scan(prompt)
        if matches:
            return FilterResult(action="block", reason="vectorscan_match")
        
        return FilterResult(action="allow")
```

#### Secret Scanner
```python
class SecretScanner:
    def __init__(self):
        self.detectors = [
            AWSKeyDetector(),
            JWTDetector(),
            PasswordDetector(),
            KoreanNationalIDDetector()
        ]
    
    async def scan(self, prompt: str) -> List[SecretMatch]:
        results = []
        for detector in self.detectors:
            matches = await detector.detect(prompt)
            results.extend(matches)
        return results

class AWSKeyDetector:
    pattern = re.compile(r'AKIA[0-9A-Z]{16}')
    
    async def detect(self, text: str) -> List[SecretMatch]:
        matches = []
        for match in self.pattern.finditer(text):
            matches.append(SecretMatch(
                type="aws_access_key",
                value=match.group(),
                start=match.start(),
                end=match.end(),
                confidence=0.95
            ))
        return matches
```

#### PII Detector (Presidio 연동)
```python
class PIIDetector:
    def __init__(self):
        self.analyzer = AnalyzerEngine()
        self.anonymizer = AnonymizerEngine()
        
        # 한국어 PII 패턴 추가
        korean_patterns = [
            Pattern(name="KR_RRN", regex=r'\d{6}-[1-4]\d{6}', score=0.9),  # 주민번호
            Pattern(name="KR_PHONE", regex=r'01[016789]-\d{3,4}-\d{4}', score=0.8)  # 휴대폰
        ]
        self.analyzer.registry.add_recognizer(PatternRecognizer("KR_CUSTOM", patterns=korean_patterns))
    
    async def detect(self, text: str) -> List[PIIMatch]:
        results = self.analyzer.analyze(text=text, language='ko')
        return [PIIMatch.from_presidio(r) for r in results]
    
    async def anonymize(self, text: str, pii_matches: List[PIIMatch]) -> str:
        anonymized = self.anonymizer.anonymize(
            text=text,
            analyzer_results=[m.to_presidio() for m in pii_matches],
            operators={"DEFAULT": OperatorConfig("replace", {"new_value": "[REDACTED]"})}
        )
        return anonymized.text
```

#### ML 기반 분류기
```python
class MLPromptClassifier:
    def __init__(self, model_path: str):
        self.tokenizer = AutoTokenizer.from_pretrained(model_path)
        self.model = AutoModelForSequenceClassification.from_pretrained(model_path)
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.model.to(self.device)
    
    async def classify(self, prompt: str) -> ClassificationResult:
        """
        분류 카테고리:
        - safe: 안전한 프롬프트
        - injection: 프롬프트 인젝션 시도
        - harmful: 유해 컨텐츠
        - sensitive: 민감 정보 처리
        """
        inputs = self.tokenizer(prompt, return_tensors="pt", truncation=True, max_length=512)
        inputs = {k: v.to(self.device) for k, v in inputs.items()}
        
        with torch.no_grad():
            outputs = self.model(**inputs)
            probabilities = torch.softmax(outputs.logits, dim=-1)
            
        predicted_class = torch.argmax(probabilities, dim=-1).item()
        confidence = probabilities[0][predicted_class].item()
        
        labels = ["safe", "injection", "harmful", "sensitive"]
        return ClassificationResult(
            category=labels[predicted_class],
            confidence=confidence,
            all_scores={label: prob.item() for label, prob in zip(labels, probabilities[0])}
        )
```

#### 임베딩 기반 필터
```python
class EmbeddingFilter:
    def __init__(self, model_name: str = "sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2"):
        self.encoder = SentenceTransformer(model_name)
        self.vector_db = QdrantClient(host="localhost", port=6333)
        self.collection_name = "blocked_prompts"
    
    async def initialize_blocklist(self, blocked_examples: List[str]):
        """금지 프롬프트 예시들을 벡터화하여 저장"""
        embeddings = self.encoder.encode(blocked_examples)
        
        points = [
            PointStruct(
                id=i,
                vector=embedding.tolist(),
                payload={"text": example, "category": "blocked"}
            )
            for i, (embedding, example) in enumerate(zip(embeddings, blocked_examples))
        ]
        
        self.vector_db.upsert(collection_name=self.collection_name, points=points)
    
    async def check_similarity(self, prompt: str, threshold: float = 0.8) -> SimilarityResult:
        """입력 프롬프트와 금지 패턴들의 유사도 검사"""
        query_embedding = self.encoder.encode([prompt])[0]
        
        search_result = self.vector_db.search(
            collection_name=self.collection_name,
            query_vector=query_embedding.tolist(),
            limit=5,
            score_threshold=threshold
        )
        
        if search_result:
            best_match = search_result[0]
            return SimilarityResult(
                is_similar=True,
                score=best_match.score,
                matched_text=best_match.payload["text"],
                action="block" if best_match.score > threshold else "warn"
            )
        
        return SimilarityResult(is_similar=False, score=0.0)
```

### 2.4 Sanitizer (프롬프트 재작성)
```python
class PromptSanitizer:
    def __init__(self):
        self.pii_detector = PIIDetector()
        self.secret_scanner = SecretScanner()
    
    async def sanitize(self, prompt: str, filter_results: List[FilterResult]) -> SanitizedPrompt:
        sanitized = prompt
        operations = []
        
        # PII 마스킹
        pii_matches = await self.pii_detector.detect(prompt)
        if pii_matches:
            sanitized = await self.pii_detector.anonymize(sanitized, pii_matches)
            operations.append("pii_masked")
        
        # 시크릿 제거
        secret_matches = await self.secret_scanner.scan(sanitized)
        for match in secret_matches:
            sanitized = sanitized.replace(match.value, "[REDACTED]")
            operations.append("secret_removed")
        
        # 인젝션 시도 무력화
        if any(r.reason == "injection_detected" for r in filter_results):
            sanitized = self.neutralize_injection(sanitized)
            operations.append("injection_neutralized")
        
        return SanitizedPrompt(
            original=prompt,
            sanitized=sanitized,
            operations=operations,
            safe_to_process=len([r for r in filter_results if r.action == "block"]) == 0
        )
    
    def neutralize_injection(self, prompt: str) -> str:
        """인젝션 시도를 무력화"""
        # 시스템 지시 무력화 패턴들을 일반 텍스트로 변환
        neutralized = re.sub(r'(?i)ignore\s+(all\s+)?previous\s+(instructions?|rules?)', 
                           'discuss ignoring previous instructions', prompt)
        neutralized = re.sub(r'(?i)you\s+are\s+now\s+', 'imagine you are now ', neutralized)
        return neutralized
```

## 3. 통합 PromptGate 서비스
```python
class PromptGateService:
    def __init__(self, config: PromptGateConfig):
        self.auth_handler = AuthenticationHandler(config.auth)
        self.policy_engine = PolicyEngine(config.policy)
        self.filters = [
            StaticPatternFilter(config.static_patterns),
            SecretScanner(),
            PIIDetector(),
            MLPromptClassifier(config.ml_model_path),
            EmbeddingFilter(config.embedding_model)
        ]
        self.sanitizer = PromptSanitizer()
        self.audit_logger = AuditLogger(config.audit)
    
    async def process_request(self, request: ChatRequest) -> ChatResponse:
        # 1. 인증 및 컨텍스트 생성
        context = await self.auth_handler.authenticate(request)
        
        # 2. 입력 정규화
        normalized_prompt = self.normalize_input(request.prompt)
        
        # 3. 필터 스택 실행
        filter_results = []
        for filter_instance in self.filters:
            result = await filter_instance.filter(normalized_prompt)
            filter_results.append(result)
            
            # Fail-Fast: 즉시 차단 필요한 경우
            if result.action == "block" and result.confidence > 0.9:
                await self.audit_logger.log_blocked_request(context, request, result)
                raise BlockedException(result.reason)
        
        # 4. 정책 평가
        policy_result = await self.policy_engine.evaluate(context, normalized_prompt)
        if not policy_result.allowed:
            await self.audit_logger.log_policy_violation(context, request, policy_result)
            raise PolicyViolationException(policy_result.reason)
        
        # 5. Sanitization
        sanitized = await self.sanitizer.sanitize(normalized_prompt, filter_results)
        if not sanitized.safe_to_process:
            raise UnsafePromptException("Prompt could not be safely sanitized")
        
        # 6. LLM 호출
        llm_response = await self.call_llm(sanitized.sanitized, context)
        
        # 7. 출력 필터링
        filtered_response = await self.filter_response(llm_response, context)
        
        # 8. 감사 로깅
        await self.audit_logger.log_successful_request(context, request, filtered_response)
        
        return filtered_response
    
    def normalize_input(self, prompt: str) -> str:
        """입력 정규화"""
        # Unicode 정규화
        normalized = unicodedata.normalize('NFKC', prompt)
        # 제어 문자 제거
        normalized = ''.join(char for char in normalized if unicodedata.category(char) != 'Cc')
        # Base64 디코딩 시도 (인코딩된 악성 페이로드 탐지)
        decoded_attempts = self.attempt_decoding(normalized)
        return normalized
```

## 4. 성능 최적화 전략

### 4.1 비동기 파이프라인
```python
async def parallel_filtering(prompt: str) -> List[FilterResult]:
    """필터들을 병렬로 실행하여 성능 향상"""
    tasks = [
        asyncio.create_task(static_filter.filter(prompt)),
        asyncio.create_task(secret_scanner.scan(prompt)),
        asyncio.create_task(pii_detector.detect(prompt)),
        asyncio.create_task(ml_classifier.classify(prompt)),
        asyncio.create_task(embedding_filter.check_similarity(prompt))
    ]
    
    results = await asyncio.gather(*tasks, return_exceptions=True)
    return [r for r in results if not isinstance(r, Exception)]
```

### 4.2 캐싱 전략
```python
class CacheManager:
    def __init__(self):
        self.redis = Redis()
        self.ttl = 3600  # 1시간
    
    async def get_cached_result(self, prompt_hash: str) -> Optional[FilterResult]:
        cached = await self.redis.get(f"filter:{prompt_hash}")
        return FilterResult.from_json(cached) if cached else None
    
    async def cache_result(self, prompt_hash: str, result: FilterResult):
        await self.redis.setex(f"filter:{prompt_hash}", self.ttl, result.to_json())

def hash_prompt(prompt: str) -> str:
    """프롬프트 해시 (개인정보 제거 후)"""
    # PII 제거 후 해싱
    clean_prompt = re.sub(r'\b\d{6}-[1-4]\d{6}\b', '[RRN]', prompt)  # 주민번호
    clean_prompt = re.sub(r'\b01[016789]-\d{3,4}-\d{4}\b', '[PHONE]', clean_prompt)  # 전화번호
    return hashlib.sha256(clean_prompt.encode()).hexdigest()
```

## 5. 모니터링 및 관측성

### 5.1 메트릭 수집
```python
from prometheus_client import Counter, Histogram, Gauge

# 메트릭 정의
requests_total = Counter('promptgate_requests_total', 'Total requests', ['tenant', 'status'])
request_duration = Histogram('promptgate_request_duration_seconds', 'Request duration')
active_filters = Gauge('promptgate_active_filters', 'Number of active filters')
blocked_requests = Counter('promptgate_blocked_requests', 'Blocked requests', ['reason'])

class MetricsCollector:
    @staticmethod
    def record_request(context: RequestContext, status: str, duration: float):
        requests_total.labels(tenant=context.tenant_id, status=status).inc()
        request_duration.observe(duration)
    
    @staticmethod
    def record_block(reason: str):
        blocked_requests.labels(reason=reason).inc()
```

### 5.2 알림 및 대시보드
```python
class AlertManager:
    def __init__(self):
        self.webhook_url = os.getenv("SLACK_WEBHOOK_URL")
    
    async def send_alert(self, alert_type: str, message: str, severity: str = "warning"):
        if severity == "critical":
            await self.send_slack_notification(f"🚨 {alert_type}: {message}")
        
        # 로그에도 기록
        logger.warning(f"Alert: {alert_type} - {message}")
    
    async def check_anomalies(self):
        """이상 징후 모니터링"""
        # 차단율 급증 감지
        recent_block_rate = await self.get_block_rate(minutes=10)
        if recent_block_rate > 0.5:  # 50% 이상
            await self.send_alert("HIGH_BLOCK_RATE", f"Block rate: {recent_block_rate:.2%}")
        
        # 반복적인 인젝션 시도
        injection_attempts = await self.get_injection_attempts_by_ip(minutes=5)
        for ip, count in injection_attempts.items():
            if count > 10:
                await self.send_alert("REPEATED_INJECTION", f"IP {ip}: {count} attempts")
```

## 6. 배포 및 운영

### 6.1 Docker 구성
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# 시스템 의존성
RUN apt-get update && apt-get install -y \
    libhyperscan5 \
    && rm -rf /var/lib/apt/lists/*

COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .

EXPOSE 8000

CMD ["uvicorn", "promptgate.main:app", "--host", "0.0.0.0", "--port", "8000"]
```

### 6.2 Kubernetes 배포
```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: promptgate
spec:
  replicas: 3
  selector:
    matchLabels:
      app: promptgate
  template:
    metadata:
      labels:
        app: promptgate
    spec:
      containers:
      - name: promptgate
        image: promptgate:latest
        ports:
        - containerPort: 8000
        env:
        - name: REDIS_URL
          value: "redis://redis-service:6379"
        - name: QDRANT_URL
          value: "http://qdrant-service:6333"
        resources:
          requests:
            memory: "512Mi"
            cpu: "250m"
          limits:
            memory: "1Gi"
            cpu: "500m"
        livenessProbe:
          httpGet:
            path: /health
            port: 8000
          initialDelaySeconds: 30
          periodSeconds: 10
```

이 설계는 확장 가능하고 성능이 최적화된 프롬프트 필터링 시스템을 제공합니다. 각 컴포넌트는 독립적으로 개발/테스트/배포가 가능하며, 실시간 모니터링과 알림 기능을 포함합니다.
